{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZWhBQCJhaD5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/shared', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1pjrBOLhuvr"
      },
      "outputs": [],
      "source": [
        "!unzip /content/shared/MyDrive/images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BwNMbT6Tsfh"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/OmarFarag95/minimum-area-bounding-rectangle-python3.git min_bbox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imgaug"
      ],
      "metadata": {
        "id": "1kn-F8bIaWHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smulcfutjICK"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "import os\n",
        "# define the base path to the input dataset and then use it to derive\n",
        "# the path to the images directory and annotation CSV file\n",
        "BASE_PATH = \"/content\"\n",
        "IMAGES_PATH = os.path.sep.join([BASE_PATH, \"images\"])\n",
        "ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"metadata.json\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-mCyZ4TkRrL"
      },
      "outputs": [],
      "source": [
        "# define the path to the base output directory\n",
        "BASE_OUTPUT = \"output\"\n",
        "if not os.path.exists(BASE_OUTPUT):\n",
        "    os.makedirs(BASE_OUTPUT)\n",
        "# define the path to the output serialized model, model training plot,\n",
        "# and testing image filenames\n",
        "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"detector.h5\"])\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
        "TEST_FILENAMES = os.path.sep.join([BASE_OUTPUT, \"test_images.txt\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm57xk1wkUde"
      },
      "outputs": [],
      "source": [
        "# initialize our initial learning rate, number of epochs to train\n",
        "# for, and the batch size\n",
        "INIT_LR = 1e-4\n",
        "NUM_EPOCHS = 2\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e44MEDsBkdmD"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.applications import VGG16, resnet\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYI4PXs_lC9C"
      },
      "outputs": [],
      "source": [
        "!cp shared/MyDrive/metadata.json /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK2tFHyYCOaS"
      },
      "outputs": [],
      "source": [
        "def get_bounding_box(points):\n",
        "\n",
        "    bot_left_x = min(point[0] for point in points)\n",
        "    bot_left_y = min(point[1] for point in points)\n",
        "    top_right_x = max(point[0] for point in points)\n",
        "    top_right_y = max(point[1] for point in points)\n",
        "\n",
        "    return [(bot_left_x, bot_left_y), (top_right_x, top_right_y)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCd2luPWPEFp"
      },
      "outputs": [],
      "source": [
        "from numpy import *\n",
        "\n",
        "from min_bbox.python.qhull_2d import *\n",
        "from min_bbox.python.min_bounding_rect import *\n",
        "\n",
        "def bounding_box_v2(points):\n",
        "    \n",
        "    xy_points = array(points)\n",
        "\n",
        "    hull_points = qhull2D(xy_points)\n",
        "\n",
        "    # Reverse order of points, to match output from other qhull implementations\n",
        "    hull_points = hull_points[::-1]\n",
        "\n",
        "    #print ('Convex hull points: \\n', hull_points, \"\\n\")\n",
        "\n",
        "    # Find minimum area bounding rectangle\n",
        "    (rot_angle, area, width, height, center_point, corner_points) = minBoundingRect(hull_points)\n",
        "\n",
        "    return corner_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPLZWwyTqir5"
      },
      "outputs": [],
      "source": [
        "v = [[246.09293140559757, 222.41169803156015],[250.44603729904748, 211.9438727322957],\n",
        "    [283.09433149992174, 279.3110343649168],\n",
        "    [297.5046130999609, 244.07283583161148],\n",
        "    [214.5704404561325, 249.46220866382959],\n",
        "    [233.4088814757176, 204.68894331699937]]\n",
        "\n",
        "bounding_box_v2(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O9QsPsDkftP"
      },
      "outputs": [],
      "source": [
        "# load the contents of the json annotations file\n",
        "print(\"[INFO] loading dataset...\")\n",
        "\n",
        "import json\n",
        "with open('metadata.json') as f:\n",
        "  metadata = json.load(f)\n",
        "\n",
        "rows = []\n",
        "set_sizes = []\n",
        "for k,v in metadata.items():\n",
        "    tuples_bounds = []\n",
        "    xy_tuples = list(set([(int(sample['x']),int(sample['y'])) for sample in v[\"bounds_x_y\"]]))\n",
        "    ## get boundarybox\n",
        "    if(len(xy_tuples)<4):\n",
        "      continue\n",
        "    bbox = bounding_box_v2(xy_tuples)\n",
        "    rows.append({k:bbox.tolist()})\n",
        "  \n",
        "# initialize the list of data (images), our target output predictions\n",
        "# (bounding box coordinates), along with the filenames of the\n",
        "# individual images\n",
        "data = []\n",
        "targets = []\n",
        "filenames = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##augmentation\n",
        "import random\n",
        "random.seed(0)\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "#select 1000 random images\n",
        "\n",
        "random_images = random.choices(rows,k=1000)\n",
        "c=0\n",
        "for image_info in random_images:\n",
        "  for k, v in image_info.items():\n",
        "\n",
        "    polygons = [[ia.Polygon(v)]]\n",
        "\n",
        "    imagePath = os.path.sep.join([IMAGES_PATH, k])\n",
        "    image = cv2.imread(imagePath)\n",
        "\n",
        "    if image_info in rows:\n",
        "      index = rows.index(image_info)\n",
        "\n",
        "      if image is not None:\n",
        "      \n",
        "        seq = iaa.CropAndPad(\n",
        "                  percent=(-0.15, 0.5),\n",
        "                  pad_mode=ia.ALL,\n",
        "                  pad_cval=(0, 0))\n",
        "        \n",
        "        images_aug, polygons_aug = seq(image=image, polygons=polygons)\n",
        "        x1,x2,x3,x4 = polygons_aug[0][0].xx\n",
        "        y1,y2,y3,y4 = polygons_aug[0][0].yy\n",
        "\n",
        "        new_coordinates = {k:[(int(x1),int(y1)),(int(x2),int(y2)),[int(x3),int(y3)],[int(x4),int(y4)]]}\n",
        "\n",
        "        # override image in its original path and update its coordinates in rows\n",
        "        cv2.imwrite(f\"IMAGES_PATH/{k}\", images_aug)\n",
        "        \n",
        "        rows[index] = new_coordinates\n",
        "\n",
        "        c+=1\n",
        "\n",
        "print(c)"
      ],
      "metadata": {
        "id": "cPOnzgLoagkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpE9xtehrcyZ"
      },
      "outputs": [],
      "source": [
        "with open('pools_ground_truth.json','w') as f:\n",
        "  json.dump(rows,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj6zhrVRlUVU"
      },
      "outputs": [],
      "source": [
        "\t# derive the path to the input image, load the image (in OpenCV\n",
        "\t# format), and grab its dimensions\n",
        "from tqdm import tqdm\n",
        "for r in tqdm(range(0,len(rows),1)):\n",
        "  example = rows[r]\n",
        "  for k,v in example.items():\n",
        "    filename = k\n",
        "    imagePath = os.path.sep.join([IMAGES_PATH, filename])\n",
        "    image = cv2.imread(imagePath)\n",
        "    if image is not None:\n",
        "      (h, w) = image.shape[:2]\n",
        "      # scale the bounding box coordinates relative to the spatial\n",
        "      # dimensions of the input image\n",
        "\n",
        "      p_1, p_2, p_3, p_4 = list(v)\n",
        "      x1 = p_1[0]/w\n",
        "      y1 = p_1[1]/h\n",
        "\n",
        "      x2 = p_2[0]/w\n",
        "      y2 = p_2[1]/h\n",
        "      \n",
        "      x3 = p_3[0]/w\n",
        "      y3 = p_3[1]/h\n",
        "      \n",
        "      x4 = p_4[0]/w\n",
        "      y4 = p_4[1]/h\n",
        "      \n",
        "    \n",
        "      image = load_img(imagePath, target_size=(150, 150))\n",
        "      image = img_to_array(image, dtype=np.uint8)\n",
        "      # update our list of data, targets, and filenames\n",
        "      data.append(image)\n",
        "      corners = [x1, y1, x2, y2, x3, y3 , x4, y4]\n",
        "      targets.append(corners)\n",
        "      filenames.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = train_test_split(data, targets, filenames, test_size=0.10,\n",
        "\trandom_state=42)"
      ],
      "metadata": {
        "id": "jzl3BvUwd1FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(trainImages, testImages) = split[:2]\n",
        "(trainTargets, testTargets) = split[2:4]\n",
        "(trainFilenames, testFilenames) = split[4:]"
      ],
      "metadata": {
        "id": "YlbWeodbeykE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainImages = np.array(trainImages,dtype=\"float32\") /255.0"
      ],
      "metadata": {
        "id": "2LjJjXZN31TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testImages = np.array(testImages,dtype=\"float32\") /255.0"
      ],
      "metadata": {
        "id": "rEkUPnzR4BHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainTargets = np.array(trainTargets, dtype=\"float32\")"
      ],
      "metadata": {
        "id": "KGF-QZ2O4H15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testTargets = np.array(testTargets, dtype=\"float32\")"
      ],
      "metadata": {
        "id": "v6fxoKNH4UC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "split = []\n",
        "targets = []\n",
        "filenames = []\n",
        "rows = []"
      ],
      "metadata": {
        "id": "xB_VcRL64dmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBQNONPoxnkP"
      },
      "outputs": [],
      "source": [
        "# data = np.array(data,dtype=\"float32\") /255.0\n",
        "# targets = np.array(targets, dtype=\"float32\")\n",
        "# # partition the data into training and testing splits using 90% of\n",
        "# # the data for training and the remaining 10% for testing\n",
        "# split = train_test_split(data, targets, filenames, test_size=0.20,\n",
        "# \trandom_state=42)\n",
        "# unpack the data split\n",
        "\n",
        "# write the testing filenames to disk so that we can use then\n",
        "# when evaluating/testing our bounding box regressor\n",
        "print('Training size:', len(trainImages))\n",
        "print('Test size:', len(testImages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGQC7DfhHc-e"
      },
      "outputs": [],
      "source": [
        "print(\"[INFO] saving testing filenames...\")\n",
        "f = open(TEST_FILENAMES, \"w\")\n",
        "f.write(\"\\n\".join(testFilenames))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LoBJ8WB3GVg"
      },
      "outputs": [],
      "source": [
        "data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phSZHjJ9yglC"
      },
      "outputs": [],
      "source": [
        "# load the VGG16 network, ensuring the head FC layers are left off\n",
        "# vgg = VGG16(weights=\"imagenet\", include_top=False,\n",
        "# \tinput_tensor=Input(shape=(150, 150, 3)))\n",
        "\n",
        "resnetn = resnet.ResNet101(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_tensor=Input(shape=(150, 150, 3))\n",
        ")\n",
        "\n",
        "# freeze all VGG layers so they will *not* be updated during the\n",
        "# training process\n",
        "resnetn.trainable = False\n",
        "# flatten the max-pooling output of VGG\n",
        "flatten = resnetn.output\n",
        "flatten = Flatten()(flatten)\n",
        "# construct a fully-connected layer header to output the predicted\n",
        "# bounding box coordinates\n",
        "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(64, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(8, activation=\"sigmoid\")(bboxHead)\n",
        "# construct the model we will fine-tune for bounding box regression\n",
        "model = Model(inputs=resnetn.input, outputs=bboxHead)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNaaDgdVKbgP"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkMIHReAzmMA"
      },
      "outputs": [],
      "source": [
        "# initialize the optimizer, compile the model, and show the model\n",
        "# summary\n",
        "opt = SGD(lr=INIT_LR)\n",
        "model.compile(loss=\"mse\", optimizer=opt)\n",
        "print(model.summary())\n",
        "# train the network for bounding box regression\n",
        "print(\"[INFO] training bounding box regressor...\")\n",
        "H = model.fit(\n",
        "\ttrainImages, trainTargets,\n",
        "\tvalidation_data=(testImages, testTargets),\n",
        "\tbatch_size=1,\n",
        "\tepochs=3,\n",
        "\tverbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2ViX9i63Nke"
      },
      "outputs": [],
      "source": [
        "# serialize the model to disk\n",
        "model.save(MODEL_PATH, save_format=\"h5\")\n",
        "# plot the model training history\n",
        "N = 3\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Bounding Box Regression Loss on Training Set\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(PLOT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVC0PlWp56Xd"
      },
      "outputs": [],
      "source": [
        "def bb_intersection_over_union(boxA, boxB):\n",
        "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
        "\txA = max(boxA[0], boxB[0])\n",
        "\tyA = max(boxA[1], boxB[1])\n",
        "\txB = min(boxA[2], boxB[2])\n",
        "\tyB = min(boxA[3], boxB[3])\n",
        "\t# compute the area of intersection rectangle\n",
        "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
        "\t# compute the area of both the prediction and ground-truth\n",
        "\t# rectangles\n",
        "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "\t# compute the intersection over union by taking the intersection\n",
        "\t# area and dividing it by the sum of prediction + ground-truth\n",
        "\t# areas - the interesection area\n",
        "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "\t# return the intersection over union value\n",
        "\treturn iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-g8ohV5UBPq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/output/detector.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BTu13KiP4DV"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('pools_ground_truth.json','r') as f:\n",
        "  ground_truth = json.load(f)\n",
        "\n",
        "def predict(imagePath):\n",
        "  image = load_img(imagePath, target_size=(150, 150))\n",
        "  image = img_to_array(image) / 255.0\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "    # make bounding box predictions on the input image\n",
        "  preds = model.predict(image)[0]\n",
        "  (x1,y1,x2,y2,x3,y3,x4,y4) = preds\n",
        "  # load the input image (in OpenCV format), resize it such that it\n",
        "  # fits on our screen, and grab its dimensions\n",
        "  image = cv2.imread(imagePath)\n",
        "  #image = imutils.resize(image, width=600)\n",
        "  (h, w) = image.shape[:2]\n",
        "  # scale the predicted bounding box coordinates based on the image\n",
        "  # dimensions\n",
        "\n",
        "  ## plot predicted bbox\n",
        "  x1 = x1*w\n",
        "  y1 = y1*h\n",
        "  x2 = x2*w\n",
        "  y2 = y2*h\n",
        "  x3 = x3*w\n",
        "  y3 = y3*h\n",
        "  x4 = x4*w\n",
        "  y4 = y4*h\n",
        "\n",
        "  #pts1 = np.array([[x1,y1],[x2,y2],[x3,y3],[x4,y4]], np.int32)\n",
        "\n",
        "  pts1 = [[x1,y1],[x2,y2],[x3,y3],[x4,y4]]\n",
        "  \n",
        "  #pts1 = pts1.reshape((-1,1,2))\n",
        "\n",
        "  #cv2.polylines(image,[pts],True,(0,255,255))\n",
        "\n",
        "\n",
        "\n",
        "  ## plot original bbox\n",
        "  for t in ground_truth:\n",
        "    for k, v in t.items():\n",
        "      if k == imagePath.split('/')[1]:\n",
        "        coors = v\n",
        "  x1,y1 = coors[0][0], coors[0][1]\n",
        "  x2,y2 = coors[1][0], coors[1][1]\n",
        "  x3,y3 = coors[2][0], coors[2][1]\n",
        "  x4,y4 = coors[3][0], coors[3][1]\n",
        "\n",
        "\n",
        "\n",
        "  pts2 = [[x1,y1],[x2,y2],[x3,y3],[x4,y4]]\n",
        "  \n",
        "  return np.array(get_bounding_box(pts1)).flatten(), np.array(get_bounding_box(pts2)).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMB5sh-WQIR2"
      },
      "outputs": [],
      "source": [
        "scores = []\n",
        "with open(\"output/test_images.txt\", 'r') as f:\n",
        "  for line in f:\n",
        "    pts1,pts2 = predict(f\"images/{line.strip()}\")\n",
        "    v = bb_intersection_over_union(pts1, pts2)\n",
        "    scores.append(v)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from scipy.stats import binned_statistic\n",
        "\n",
        "data = scores\n",
        "bin_means = binned_statistic(data, data, bins=10, range=(0, 1))[0]"
      ],
      "metadata": {
        "id": "3on-OLQ6mef5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.hist(scores, density=False, bins=10)  # density=False would make counts\n",
        "plt.ylabel('Counts')\n",
        "plt.xlabel('IoU');\n",
        "plt.savefig('iou_metric.png')"
      ],
      "metadata": {
        "id": "jVtCZh-Bou0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vlaWkSBxowUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "swimming-pools-tightest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}